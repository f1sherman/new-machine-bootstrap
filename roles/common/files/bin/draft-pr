#!/usr/bin/env ruby
# draft-pr - Script to generate a PR description with Claude and create a draft PR

require 'json'
require 'optparse'
require 'tmpdir'
require 'fileutils'
require 'open3'

# Parse command line options
options = {}
OptionParser.new do |opts|
  opts.banner = "Usage: draft-pr [options]"
  opts.on("-h", "--help", "Show this help message") do
    puts opts
    exit
  end
end.parse!

# Check for required dependencies
%w[git gh curl nvim].each do |cmd|
  unless system("which #{cmd} > /dev/null 2>&1")
    puts "Error: #{cmd} is not installed or not in PATH"
    exit 1
  end
end

# Check for required API keys
missing_keys = []
missing_keys << "ANTHROPIC_API_KEY" unless ENV["ANTHROPIC_API_KEY"]
missing_keys << "OPENAI_API_KEY" unless ENV["OPENAI_API_KEY"]
unless missing_keys.empty?
  puts "Error: Missing required environment variables: #{missing_keys.join(', ')}"
  exit 1
end

# Create a temporary directory
temp_dir = Dir.mktmpdir
puts "Working directory for this PR: #{temp_dir}"

# Helper functions to run shell commands and handle errors
def run_command(command, error_message)
  system(command)
  unless $?.success?
    puts "Error: #{error_message}"
    exit 1
  end
end

def run_curl(command, label, response_path)
  stdout, stderr, status = Open3.capture3(command)
  File.write(response_path, stdout)
  unless status.success?
    message = stderr.strip
    message = stdout.strip if message.empty?
    raise "#{label} API call failed: #{message}"
  end
  stdout
end

def generate_anthropic_pr(prompt_file:, request_file:, response_file:, pr_file:, model:, label:)
  request = {
    model: model,
    max_tokens: 10000,
    messages: [
      {
        role: "user",
        content: File.read(prompt_file)
      }
    ]
  }

  File.write(request_file, JSON.pretty_generate(request))

  curl_command = <<~CMD
    curl -sS https://api.anthropic.com/v1/messages \
      -H "Content-Type: application/json" \
      -H "x-api-key: #{ENV.fetch("ANTHROPIC_API_KEY")}" \
      -H "anthropic-version: 2023-06-01" \
      --data @"#{request_file}"
  CMD

  raw_response = run_curl(curl_command, label, response_file)

  begin
    response = JSON.parse(raw_response)
  rescue JSON::ParserError => e
    raise "#{label} response parse failed: #{e.message}. Check #{response_file}"
  end

  if response["error"]
    raise "#{label} API error: #{response.dig("error", "message")}"
  end

  pr_text = response.dig("content", 0, "text")
  unless pr_text.is_a?(String)
    raise "#{label} response missing text. Check #{response_file}"
  end

  File.write(pr_file, pr_text)
  pr_text
end

def generate_openai_pr(prompt_file:, request_file:, response_file:, pr_file:, model:, label:)
  request = {
    model: model,
    messages: [
      {
        role: "user",
        content: File.read(prompt_file)
      }
    ],
    max_completion_tokens: 10000
  }

  File.write(request_file, JSON.pretty_generate(request))

  curl_command = <<~CMD
    curl -sS https://api.openai.com/v1/chat/completions \
      -H "Content-Type: application/json" \
      -H "Authorization: Bearer #{ENV.fetch("OPENAI_API_KEY")}" \
      --data @"#{request_file}"
  CMD

  raw_response = run_curl(curl_command, label, response_file)

  begin
    response = JSON.parse(raw_response)
  rescue JSON::ParserError => e
    raise "#{label} response parse failed: #{e.message}. Check #{response_file}"
  end

  if response["error"]
    message = response.dig("error", "message") || response["error"].to_s
    raise "#{label} API error: #{message}"
  end

  pr_text = response.dig("choices", 0, "message", "content")
  unless pr_text.is_a?(String)
    raise "#{label} response missing content. Check #{response_file}"
  end

  File.write(pr_file, pr_text)
  pr_text
end

# Git operations
puts "Checking origin tracking for current branch..."
current_branch = `git branch --show-current`.strip
upstream = `git rev-parse --abbrev-ref #{current_branch}@{upstream} 2>/dev/null`.strip
if upstream.empty?
  puts "Setting up origin tracking..."
  run_command("git push -u origin #{current_branch}", "Failed to set up origin tracking")
end

puts "Fetching latest main from origin..."
run_command("git fetch origin main", "Failed to fetch latest main from origin")

puts "Rebasing on latest main..."
unless system("git rebase origin/main")
  puts "Error: Failed to rebase on latest main"
  puts "Please resolve conflicts and run git rebase --continue, then try again"
  exit 1
end

puts "Pushing to origin..."
run_command("git push origin HEAD --force-with-lease", "Failed to push changes")

# Get ticket number from commits (if any)
ticket = `git log origin/main... | grep 'Connected to' | cut -d ' ' -f 7 | tail -n 1`.strip

# Fallback: extract ticket ID from branch name if not found in commits
if ticket.empty?
  branch = `git branch --show-current`.strip
  ticket_match = branch.match(/^([A-Z]+-\d+)\//)
  ticket = ticket_match ? ticket_match[1] : ""
else
  branch = `git branch --show-current`.strip
end

# Create title from branch name
title = branch.gsub(/-/, ' ')

# Create file paths
commit_file = File.join(temp_dir, "commits.md")
code_diff_file = File.join(temp_dir, "code_diff.md")
prompt_file = File.join(temp_dir, "pr_prompt.txt")
opus_request_file = File.join(temp_dir, "opus_request.json")
opus_response_file = File.join(temp_dir, "opus_response.json")
opus_pr_file = File.join(temp_dir, "opus_pr.md")
gpt_request_file = File.join(temp_dir, "gpt_request.json")
gpt_response_file = File.join(temp_dir, "gpt_response.json")
gpt_pr_file = File.join(temp_dir, "gpt_pr.md")
pr_template_file = File.join(temp_dir, "pr_template.md")

# Get commit messages
puts "Getting commit messages..."
run_command("git log --pretty=format:\"* %s%n%n%b\" --no-merges origin/main...HEAD > #{commit_file}",
            "Failed to get commit messages")

# Get code diff
puts "Generating code diff..."
File.open(code_diff_file, 'w') do |f|
  f.puts "```diff"
  f.puts `git diff origin/main...HEAD`
  f.puts "```"
end

# Create PR prompt
puts "Creating PR prompt..."
prompt_template = <<~EOL
  You are an expert software engineer helping draft a pull request description. Based on these commit messages and code changes, generate a PR description that follows this exact format:

  ## Purpose

  <brief summary of what this PR does and why>

  ## Context

  <more detailed context about the changes, design decisions, and implementation approach>

  ## Guidance

  <specific questions or areas where you want reviewer feedback>

  ## AI Tools Used

  Claude Code

  ## Tasks

  <a checklist of tasks for the author (me) to complete. This could include things like updating or removing secrets from Github, configuration changes in external tools, etc. Format these as checkboxes like '- [ ] Task item'>

  ## Testing

  <a checklist of testing steps for the author (me) to verify I've completed. Format these as checkboxes like '- [ ] Test item'>

  The PR description should be concise but informative. Focus on explaining the purpose, approach, and impact of the changes. The testing section should include a practical checklist that I (the author) can use to verify my work before requesting review, with each item as a checkbox using markdown '- [ ]' format. Don't include the commits themselves as I'll add those separately.
EOL

File.open(prompt_file, 'w') do |f|
  f.puts prompt_template
  f.puts
  f.puts "## Commit Messages:"
  f.puts File.read(commit_file)
  f.puts
  f.puts "## Code Changes:"
  f.puts File.read(code_diff_file)
end

# Generate PR descriptions concurrently
results = {}
errors = {}

threads = []
threads << Thread.new do
  begin
    puts "Generating PR description with Claude Opus 4.5..."
    results[:opus] = generate_anthropic_pr(
      prompt_file: prompt_file,
      request_file: opus_request_file,
      response_file: opus_response_file,
      pr_file: opus_pr_file,
      model: "claude-opus-4-5-20251101",
      label: "Claude Opus 4.5"
    )
  rescue => e
    errors[:opus] = e
  end
end

threads << Thread.new do
  begin
    puts "Generating PR description with OpenAI GPT-5.2..."
    results[:gpt] = generate_openai_pr(
      prompt_file: prompt_file,
      request_file: gpt_request_file,
      response_file: gpt_response_file,
      pr_file: gpt_pr_file,
      model: "gpt-5.2",
      label: "OpenAI GPT-5.2"
    )
  rescue => e
    errors[:gpt] = e
  end
end

threads.each(&:join)

unless errors.empty?
  messages = errors.map do |key, err|
    label = key == :opus ? "Claude Opus 4.5" : "OpenAI GPT-5.2"
    "#{label} failed: #{err.message}"
  end
  puts "Error generating PR descriptions:\n#{messages.join("\n")}"
  exit 1
end

opus_pr = results[:opus]
gpt_pr = results[:gpt]

# Create the final PR template
puts "Creating PR template..."
File.open(pr_template_file, 'w') do |f|
  f.puts opus_pr
  f.puts
  f.puts "---"
  f.puts
  f.puts gpt_pr
  f.puts
  f.puts "## Artifacts"
  f.puts
  f.puts "[#{ticket}](https://betterup.atlassian.net/browse/#{ticket})" unless ticket.empty?
  f.puts
  f.puts "## Commits"
  f.puts
  f.puts File.read(commit_file)
end

# Show preview
puts "Preview of PR template:"
puts File.read(pr_template_file)

# Open vim for editing
puts "Opening editor for modifications..."
run_command("nvim #{pr_template_file}", "Failed to open nvim")

# Create draft PR using gh CLI
puts "Creating draft PR..."
run_command("gh pr create --base main --body-file \"#{pr_template_file}\" --title \"#{title}\" --draft",
            "Failed to create PR")

# Open the PR in browser (skip in Codespaces since we're in SSH)
unless ENV["CODESPACES"]
  system("gh pr view --web")
end

# Keep temporary files for debugging
puts
puts "Temporary files kept for debugging in: #{temp_dir}"
puts "These files will be cleaned up automatically by your system eventually."
puts "Files available for inspection:"
puts "  - #{pr_template_file} (Final PR template)"
puts "  - #{commit_file} (Commit messages)"
puts "  - #{code_diff_file} (Code diff)"
puts "  - #{prompt_file} (PR prompt)"
puts "  - #{opus_request_file} (Claude Opus 4.5 request JSON)"
puts "  - #{opus_response_file} (Claude Opus 4.5 API response)"
puts "  - #{opus_pr_file} (Claude Opus 4.5 PR content)"
puts "  - #{gpt_request_file} (OpenAI GPT-5.2 request JSON)"
puts "  - #{gpt_response_file} (OpenAI GPT-5.2 API response)"
puts "  - #{gpt_pr_file} (OpenAI GPT-5.2 PR content)"
